{"cells":[{"metadata":{"_uuid":"bda30bb60722647ec9219ff4644dbf09991582bb"},"cell_type":"markdown","source":"* **This kernel is based on one of the exercises in the excellent book: [Deep Learning with Python by Francois Chollet](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438)\n**\n* The kernel imports the IMDB reviews (originally text - already transformed by Keras to integers using a dictionary)\n* Vectorizes and normalizes the data\n* Compiles a multi layers NN\n* Monitors the learning / validation curves for loss and accuracy\n* Try and error with different layers and hidden units\n* Employs L1 and L2 weight regularization\n* Implements a DROPOUT layer\n\n* The above mentioned book is a **MUST READ**.\n* *Thanks Francois for an amazing book !*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# IMPORT MODULES\n# TURN ON the GPU !!!\n# If importing dataset from outside - like this IMDB - Internet must be \"connected\"\n\nimport os\nfrom operator import itemgetter    \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nget_ipython().magic(u'matplotlib inline')\nplt.style.use('ggplot')\n\nimport tensorflow as tf\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils, to_categorical\n \nfrom keras.datasets import imdb\n\nprint(os.getcwd())\nprint(\"Modules imported \\n\")\nprint(\"Files in current directory:\")\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\")) #check the files available in the directory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2309a027762ad0f83018d32eb194af33bf128021","collapsed":true},"cell_type":"code","source":"# LOAD IMDB DATA\n\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\nnum_words=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"563a5a8c65a26338fc42b0bcad94e3e4782be0b6"},"cell_type":"code","source":"print(\"train_data \", train_data.shape)\nprint(\"train_labels \", train_labels.shape)\nprint(\"_\"*100)\nprint(\"test_data \", test_data.shape)\nprint(\"test_labels \", test_labels.shape)\nprint(\"_\"*100)\nprint(\"Maximum value of a word index \")\nprint(max([max(sequence) for sequence in train_data]))\nprint(\"Maximum length num words of review in train \")\nprint(max([len(sequence) for sequence in train_data]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5db6853639628b911ccdd0e0ecc484f4beeb9284"},"cell_type":"code","source":"# See an actual review in words\n# Reverse from integers to words using the DICTIONARY (given by keras...need to do nothing to create it)\n\nword_index = imdb.get_word_index()\n\nreverse_word_index = dict(\n[(value, key) for (key, value) in word_index.items()])\n\ndecoded_review = ' '.join(\n[reverse_word_index.get(i - 3, '?') for i in train_data[123]])\n\nprint(decoded_review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"080f1f790e7294231c1e62c1688666589d51a200","collapsed":true},"cell_type":"code","source":"# VECTORIZE as one cannot feed integers into a NN \n# Encoding the integer sequences into a binary matrix - one hot encoder basically\n# From integers representing words, at various lengths - to a normalized one hot encoded tensor (matrix) of 10k columns\n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f012f8661fd781a95bd6c01197b7a93e944ff38e"},"cell_type":"code","source":"x_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\nprint(\"x_train \", x_train.shape)\nprint(\"x_test \", x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d561665727e49217e14c86804f148adb6899a7b7"},"cell_type":"code","source":"# VECTORIZE the labels too - NO INTEGERS only floats into a tensor...(rare exceptions)\n\ny_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')\nprint(\"y_train \", y_train.shape)\nprint(\"y_test \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bccb4315c1d69c18cab22a633dc68abdff4b35fb"},"cell_type":"code","source":"# Set a VALIDATION set\n\nx_val = x_train[:10000]\npartial_x_train = x_train[10000:]\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]\n\nprint(\"x_val \", x_val.shape)\nprint(\"partial_x_train \", partial_x_train.shape)\nprint(\"y_val \", y_val.shape)\nprint(\"partial_y_train \", partial_y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf2a055346b2e3252b103f1d0bab9e786e5d5eba"},"cell_type":"code","source":"# NN MODEL\n\n# Use of DROPOUT\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.001), activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.001),activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n# Use of REGULARIZATION\n#model = models.Sequential()\n#model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu', input_shape=(10000,)))\n#model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu'))\n#model.add(layers.Dense(1, activation='sigmoid'))\n\n# REGULARIZERS L1 L2\n#regularizers.l1(0.001)\n#regularizers.l2(0.001)\n#regularizers.l1_l2(l1=0.001, l2=0.001)\n\n# OPTIMIZERS\n#model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\n#model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"356f3351bfa767aca48e91d305961dda2d3b9a9d","scrolled":true},"cell_type":"code","source":"# FIT / TRAIN model\n\nNumEpochs = 10\nBatchSize = 512\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n\nhistory = model.fit(partial_x_train, partial_y_train, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, y_val))\n\nresults = model.evaluate(x_test, y_test)\nprint(\"_\"*100)\nprint(\"Test Loss and Accuracy\")\nprint(\"results \", results)\nhistory_dict = history.history\nhistory_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41489e2204c5d4159f5c90a350aa3ad839e03355"},"cell_type":"code","source":"# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abfa37123f9f403041a1c12edd6a87070b78c5ef"},"cell_type":"code","source":"# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\nepochs = range(1, (len(history_dict['acc']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fda90fab3c7038df8291fa4f3185fbb62e9aed4"},"cell_type":"code","source":"# PREDICT\n\nmodel.predict(x_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}