{"cells":[{"metadata":{"_uuid":"a40153021c15eb45ff2026d456945763c79c11ef"},"cell_type":"markdown","source":"# Boston house price prediction"},{"metadata":{"_uuid":"8731c498e69012e3b8e407399ab813f0f15fc732"},"cell_type":"markdown","source":"The problem that we are going to solve here is that given a set of features that describe a house in Boston, our machine learning model must predict the house price. To train our machine learning model with boston housing data, we will be using scikit-learn‚Äôs boston dataset.\n\nIn this dataset, each row describes a boston town or suburb. There are 506 rows and 13 attributes (features) with a target column (price).\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names"},{"metadata":{"trusted":true,"_uuid":"c72424fcefad6b27f904bdc3301ff272baf3b212"},"cell_type":"code","source":"# Importing the libraries \nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"7ad691aeebc4b3845eefa1ac8ca32fc4b631209d"},"cell_type":"code","source":"# Importing the Boston Housing dataset\nfrom sklearn.datasets import load_boston\nboston = load_boston()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5853d3c3d9e4b52f37ea42665f573bfd92941ddf"},"cell_type":"code","source":"# Initializing the dataframe\ndata = pd.DataFrame(boston.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b6f7755accf4b1c5f4e90a3d4aea7f41f89a482"},"cell_type":"code","source":"# See head of the dataset\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"6ecbc294bdbabbafee3893b5c66bd89709d6a069"},"cell_type":"code","source":"#Adding the feature names to the dataframe\ndata.columns = boston.feature_names\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45b04cfb9bfc68cfab0ebf412ad402bac6fc5343"},"cell_type":"markdown","source":"CRIM per capita crime rate by town <br>\nZN proportion of residential land zoned for lots over 25,000 sq.ft. <br>\nINDUS proportion of non-retail business acres per town <br>\nCHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) <br>\nNOX nitric oxides concentration (parts per 10 million) <br>\nRM average number of rooms per dwelling <br>\nAGE proportion of owner-occupied units built prior to 1940 <br>\nDIS weighted distances to five Boston employment centres <br>\nRAD index of accessibility to radial highways <br>\nTAX full-value property-tax rate per 10,000usd <br>\nPTRATIO pupil-teacher ratio by town <br>\nB 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town <br>\nLSTAT % lower status of the population <br>"},{"metadata":{"_uuid":"d16fdd57c4ee58a812935d5a3e1f4bfe5923e23e"},"cell_type":"markdown","source":"Each record in the database describes a Boston suburb or town."},{"metadata":{"trusted":true,"_uuid":"293641aa8ae59c57884bd19c0ee6fc43143b19b8"},"cell_type":"code","source":"#Adding target variable to dataframe\ndata['PRICE'] = boston.target \n# Median value of owner-occupied homes in $1000s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5edd7daea054f44df78e956846596fd9e82274f"},"cell_type":"code","source":"#Check the shape of dataframe\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"264fd03458b3b349d2d52ac02b83e2e85b6190b2"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a745ede36d316c539a7c8d53ced27b9ccae85b2"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e86b006860c2efe29294aca3ba4419d9c758ced2"},"cell_type":"code","source":"# Identifying the unique number of values in the dataset\ndata.nunique()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"cef1bbf6ab92b5cd42a9a0771a24f48a09acf218"},"cell_type":"code","source":"# Check for missing values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d77b2f0e188a0bad15574340c61fad981a571b5"},"cell_type":"code","source":"# See rows with missing values\ndata[data.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"fd9f1bad153f453931265ca2c2662a138a6737b3"},"cell_type":"code","source":"# Viewing the data statistics\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f35fcf15ca8787f7c2b27c9567e02bec12dd8232"},"cell_type":"code","source":"# Finding out the correlation between the features\ncorr = data.corr()\ncorr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a2f669e42f1c4da0678d3012fe90996ce8dc476"},"cell_type":"code","source":"# Plotting the heatmap of correlation between features\nplt.figure(figsize=(20,20))\nsns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"e8b29232f337d8d269fdeab876ecf1b6cf692556"},"cell_type":"code","source":"# Spliting target variable and independent variables\nX = data.drop(['PRICE'], axis = 1)\ny = data['PRICE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c44aa7df1ef21f85c1baba09dbb5807c223c51a"},"cell_type":"code","source":"# Splitting to training and testing data\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af76da42b96f93ae8bd6234053182ecee90f255e"},"cell_type":"markdown","source":"# Linear regression"},{"metadata":{"_uuid":"f585ceafa562d74250058bf0ff05cdf8ccebb577"},"cell_type":"markdown","source":"#### Training the model"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"74c1df4cd4ba074712c8fe65802acc568e0b6ba9"},"cell_type":"code","source":"# Import library for Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\n# Create a Linear regressor\nlm = LinearRegression()\n\n# Train the model using the training sets \nlm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"998fb3c39c9a86eb1bcd4d921dd183a6491335d7"},"cell_type":"code","source":"# Value of y intercept\nlm.intercept_","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"014c51bc46bb492a44f253c3c04e113ddbc39af6"},"cell_type":"code","source":"#Converting the coefficient values to a dataframe\ncoeffcients = pd.DataFrame([X_train.columns,lm.coef_]).T\ncoeffcients = coeffcients.rename(columns={0: 'Attribute', 1: 'Coefficients'})\ncoeffcients","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a51c9fddb34d1d64b08a1ae5b52a0fa5de220c2"},"cell_type":"markdown","source":"#### Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"fbf88954f6ea78c339dfd4d1bbb4731fe1b3c489"},"cell_type":"code","source":"# Model prediction on train data\ny_pred = lm.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"40c2d862d0798c825949e665b23a0d93e7acbf22"},"cell_type":"code","source":"# Model Evaluation\nprint('R^2:',metrics.r2_score(y_train, y_pred))\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_train, y_pred))\nprint('MSE:',metrics.mean_squared_error(y_train, y_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7eceb24e150551eff5f3c946772437ffcfdce8d"},"cell_type":"markdown","source":"ùëÖ^2 : It is a measure of the linear relationship between X and Y. It is interpreted as the proportion of the variance in the dependent variable that is predictable from the independent variable.\n\nAdjusted ùëÖ^2 :The adjusted R-squared compares the explanatory power of regression models that contain different numbers of predictors.\n\nMAE : It is the mean of the absolute value of the errors. It measures the difference between two continuous variables, here actual and predicted values of y.¬†\n\nMSE: The¬†mean square error¬†(MSE) is just like the MAE, but¬†squares¬†the difference before summing them all instead of using the absolute value.¬†\n\nRMSE: The¬†mean square error¬†(MSE) is just like the MAE, but¬†squares¬†the difference before summing them all instead of using the absolute value.¬†\n\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"c00f457edc850676c7ac951f2a77994bc798f709"},"cell_type":"code","source":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(y_train, y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65b07c5f88bbc8863b56057568bb09443484d806"},"cell_type":"code","source":"# Checking residuals\nplt.scatter(y_pred,y_train-y_pred)\nplt.title(\"Predicted vs residuals\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Residuals\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c399b5c2f66818caf7600c0f10338c0ce5afebc8"},"cell_type":"markdown","source":"There is no pattern visible in this plot and values are distributed equally around zero. So Linearity assumption is satisfied"},{"metadata":{"trusted":true,"_uuid":"9814045d0aaa99146a32653f4e5449a11b05ff8f"},"cell_type":"code","source":"# Checking Normality of errors\nsns.distplot(y_train-y_pred)\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d767c0ab0732c66838be5aecf56f23f859c1021"},"cell_type":"markdown","source":"Here the residuals are normally distributed. So normality assumption is satisfied"},{"metadata":{"_uuid":"a91b3c5ee714c81642b90d02760c7e10f827fd48"},"cell_type":"markdown","source":"#### For test data"},{"metadata":{"trusted":true,"_uuid":"d1c22569bf33b54bc8e67dd9768beeb48520c5f0"},"cell_type":"code","source":"# Predicting Test data with the model\ny_test_pred = lm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bd7bf701f57b013f7b4bb3ee30debdf216647f6"},"cell_type":"code","source":"# Model Evaluation\nacc_linreg = metrics.r2_score(y_test, y_test_pred)\nprint('R^2:', acc_linreg)\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\nprint('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7a9ed698fd4f011bae24ce4b966317de91f9d91"},"cell_type":"markdown","source":"Here the model evaluations scores are almost matching with that of train data. So the model is not overfitting."},{"metadata":{"_uuid":"6d4c438bc27d2e3093f625e04ee9aeb5282a4710"},"cell_type":"markdown","source":"# Random Forest Regressor "},{"metadata":{"_uuid":"7f50fab16d7fc4871f56d60d84ff245e16a70172"},"cell_type":"markdown","source":"#### Train the model"},{"metadata":{"trusted":true,"_uuid":"34e2ffdaf66c5bb6d30daa5acd5276a6da21e809"},"cell_type":"code","source":"# Import Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Create a Random Forest Regressor\nreg = RandomForestRegressor()\n\n# Train the model using the training sets \nreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b1ab519a44ec90e993e152eb908f867db07f381"},"cell_type":"markdown","source":"### Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"96b76c70a914d3b9d20a4aefe0742e625890f73e"},"cell_type":"code","source":"# Model prediction on train data\ny_pred = reg.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a0a1be1b53f2e4e5ee260d9bc27099403c703fa"},"cell_type":"code","source":"# Model Evaluation\nprint('R^2:',metrics.r2_score(y_train, y_pred))\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_train, y_pred))\nprint('MSE:',metrics.mean_squared_error(y_train, y_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b02cec6f66440794e5108df5f5474e920d1fe98a"},"cell_type":"code","source":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(y_train, y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daf4eff8a6666267fda29751966ec7d6fe7e6d98"},"cell_type":"code","source":"# Checking residuals\nplt.scatter(y_pred,y_train-y_pred)\nplt.title(\"Predicted vs residuals\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Residuals\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5beaa188e7383427c260763f5ce481bdbf11bb8b"},"cell_type":"markdown","source":"#### For test data"},{"metadata":{"trusted":true,"_uuid":"78c445bf1a9e2a03850b6042742b53e0f1620d7c"},"cell_type":"code","source":"# Predicting Test data with the model\ny_test_pred = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb95f57e021dcda311e9da08163f9ca0479dc600"},"cell_type":"code","source":"# Model Evaluation\nacc_rf = metrics.r2_score(y_test, y_test_pred)\nprint('R^2:', acc_rf)\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\nprint('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67ad608854dda892dfbb07892b9386fd46b19b3b"},"cell_type":"markdown","source":"# XGBoost Regressor"},{"metadata":{"_uuid":"4cc3f92ac593e0fc054716eefabd5e01f4bec9b4"},"cell_type":"markdown","source":"#### Training the model"},{"metadata":{"trusted":true,"_uuid":"c6d191c4c3ded9af5367084d4261e22e499ffa6d"},"cell_type":"code","source":"# Import XGBoost Regressor\nfrom xgboost import XGBRegressor\n\n#Create a XGBoost Regressor\nreg = XGBRegressor()\n\n# Train the model using the training sets \nreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7625a387d88cfe7a97bff1955ecb4f336dd20743"},"cell_type":"markdown","source":"max_depth (int) ‚Äì Maximum tree depth for base learners.\n\nlearning_rate (float) ‚Äì Boosting learning rate (xgb‚Äôs ‚Äúeta‚Äù)\n\nn_estimators (int) ‚Äì Number of boosted trees to fit.\n\ngamma (float) ‚Äì Minimum loss reduction required to make a further partition on a leaf node of the tree.\n\nmin_child_weight (int) ‚Äì Minimum sum of instance weight(hessian) needed in a child.\n\nsubsample (float) ‚Äì Subsample ratio of the training instance.\n\ncolsample_bytree (float) ‚Äì Subsample ratio of columns when constructing each tree.\n\nobjective (string or callable) ‚Äì Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below).\n\nnthread (int) ‚Äì Number of parallel threads used to run xgboost. (Deprecated, please use n_jobs)\n\nscale_pos_weight (float) ‚Äì Balancing of positive and negative weights.\n"},{"metadata":{"_uuid":"0615c8ed00975272b8caa2d6aad13adcf677f44c"},"cell_type":"markdown","source":"### Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"242ef4a922e91e75c0d61be702a3c6ef57ac955b"},"cell_type":"code","source":"# Model prediction on train data\ny_pred = reg.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41e25ef2b58e5b0a5c1300425a4282dd8e0a0955"},"cell_type":"code","source":"# Model Evaluation\nprint('R^2:',metrics.r2_score(y_train, y_pred))\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_train, y_pred))\nprint('MSE:',metrics.mean_squared_error(y_train, y_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85df05cbc687636df454c4e5e0059492bcd77ce6"},"cell_type":"code","source":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(y_train, y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04df87e9670c3cc1b07d4525dd67605d8d4eb542"},"cell_type":"code","source":"# Checking residuals\nplt.scatter(y_pred,y_train-y_pred)\nplt.title(\"Predicted vs residuals\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Residuals\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e48d52c87b4fe3b93a6068349c4d7401a10307f4"},"cell_type":"markdown","source":"#### For test data"},{"metadata":{"trusted":true,"_uuid":"df2ead1c6dcee03e3143e1e139a42b050e1de3ca"},"cell_type":"code","source":"#Predicting Test data with the model\ny_test_pred = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cfe00224641dca28997a6f4b05bdc2dece952ca"},"cell_type":"code","source":"# Model Evaluation\nacc_xgb = metrics.r2_score(y_test, y_test_pred)\nprint('R^2:', acc_xgb)\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\nprint('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"561bc791f61ca4cac779395f30cfaec14bb59e1e"},"cell_type":"markdown","source":"# SVM Regressor"},{"metadata":{"trusted":true,"_uuid":"e7d40a6ff89aa230a6e3bea996aa93316300ed9a"},"cell_type":"code","source":"# Creating scaled set to be used in model to improve our results\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe78f0e481006b004881a6c13750e80ff9de4f00"},"cell_type":"markdown","source":"#### Train the model"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"519df75a3e65e691e203efa21693814f25cc305d"},"cell_type":"code","source":"# Import SVM Regressor\nfrom sklearn import svm\n\n# Create a SVM Regressor\nreg = svm.SVR()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35d7e0b6ac09dfdca6d9fc5328cf42bfb7b287ca"},"cell_type":"code","source":"# Train the model using the training sets \nreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f3a0067425edc3f1dfa6feb4526d120ed23c0e7"},"cell_type":"markdown","source":"C : float, optional (default=1.0): The penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly.\n\nkernel : string, optional (default='rbf‚Äô): kernel parameters selects the type of hyperplane used to separate the data. It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed‚Äô or a callable.\n\ndegree : int, optional (default=3): Degree of the polynomial kernel function (‚Äòpoly‚Äô). Ignored by all other kernels.\n\ngamma : float, optional (default='auto‚Äô): It is for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set. Current default is 'auto' which uses 1 / n_features.\n\ncoef0 : float, optional (default=0.0): Independent term in kernel function. It is only significant in 'poly' and 'sigmoid'.\n\nshrinking : boolean, optional (default=True): Whether to use the shrinking heuristic."},{"metadata":{"_uuid":"eb1fe4ad5131395f7a6936a8747e5677fdd83d40"},"cell_type":"markdown","source":"#### Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"829074eccb90898b90ce05559579d433ebd7d6d2"},"cell_type":"code","source":"# Model prediction on train data\ny_pred = reg.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8a70552dd201f2ee41d9e66fc976807cf6aeff4"},"cell_type":"code","source":"# Model Evaluation\nprint('R^2:',metrics.r2_score(y_train, y_pred))\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_train, y_pred))\nprint('MSE:',metrics.mean_squared_error(y_train, y_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"378d3d7cef08763ac0ba33f678fe312b489abb10"},"cell_type":"code","source":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(y_train, y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61aa86222c5a5f704cb9de6d3f4a76302ea2bb2e"},"cell_type":"code","source":"# Checking residuals\nplt.scatter(y_pred,y_train-y_pred)\nplt.title(\"Predicted vs residuals\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Residuals\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87809e684366967bdd103085e5f041692911fae8"},"cell_type":"markdown","source":"#### For test data"},{"metadata":{"trusted":true,"_uuid":"0c4a9a7cd7ec0910b662763d1a93ada5ec2aab61"},"cell_type":"code","source":"# Predicting Test data with the model\ny_test_pred = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9184c04875d7b80ee068c5fa158fbc96ba8491e3"},"cell_type":"code","source":"# Model Evaluation\nacc_svm = metrics.r2_score(y_test, y_test_pred)\nprint('R^2:', acc_svm)\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\nprint('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"011417c6027493065c9ab2e7244ea968d32cc93b"},"cell_type":"markdown","source":"# Evaluation and comparision of all the models"},{"metadata":{"trusted":true,"_uuid":"57ebbecee4e34cd60bd0f03cc2f291ff52b263cc"},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Linear Regression', 'Random Forest', 'XGBoost', 'Support Vector Machines'],\n    'R-squared Score': [acc_linreg*100, acc_rf*100, acc_xgb*100, acc_svm*100]})\nmodels.sort_values(by='R-squared Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73de738a3bf2d3f9eca0e2906034403dd8c89450"},"cell_type":"markdown","source":"## Hence XGBoost Regression works the best for this dataset.****"},{"metadata":{"_uuid":"67841a26d8a3622fef97a1044ffbce0255d4d3d2"},"cell_type":"markdown","source":"### Please upvote if you found this kernel useful! :) <br>\n### Feedback is greatly appreciated!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}